#!/bin/bash

#########################################################
# 
# Platform: NCI Gadi HPC
# Description: merge recalibrated split BAM files into one final BAM
# per sample, parallelising tasks by sample
# Details:
# 	Each sample has 3367 recalibrated BAM files to be merged into one 
# 	final BAM per sample. Process blood and tumour as separate jobs 
#	due to ~ double walltime requirement for tumour. This step can 
#	be performed with SAMbamba (this script) or GATK GatherBamFiles 
#	(see bqsr_merge_GATK_run_parallel). GATK is slower but costs less 
#	SUs. SAMbamba is faster but uses more SUs. For normal (30X) samples, 
#	request 24 CPU per sample and 4 GB per CPU, giving 24 threads
#	to SAMbamba. For tumour samples (60X) allow 48 CPU per sample and 
#	4 GB RAM per CPU, but still only provide 24 threads to SAMbamba.
#	If single tumour samples are run, the optimal setting is 36 CPU 
#	worth of RAM and 24 CPU SAMbamba threads, but this division is 
#	not possible with this parallel method. When the Broadwell nodes
# 	come online on Gadi, this script should be modified to use those
#	nodes as the RAM per CPU is perfect for merging. We have had issues
#	with SAMbamba after and Gadi downtime for system upgrades: SAMbamba
#	ceases to be able to merge so many files, and results in jobs that
#	hang idle (low CPU and MEM usage) indefinitely, producing no output. 
#	I suspect it's something to do with htslib but that's just a hunch.
#	A re-install of SAMbamba has so far worked. Need to investigate 
#	whether a containerised SAMbamba will be immune to these issues.
#	If you encounter this, kill the job (first wait at least half an hour 
#	as it can take some time for outputs to appear), re-install SAMbamba 
#	from source, and resubmit. If that fails, use the GATK method.   
# Author: Cali Willet
# cali.willet@sydney.edu.au
# Date last modified: 14/10/2020
#
# If you use this script towards a publication, please acknowledge the
# Sydney Informatics Hub (or co-authorship, where appropriate).
#
# Suggested acknowledgement:
# The authors acknowledge the scientific and technical assistance 
# <or e.g. bioinformatics assistance of <PERSON>> of Sydney Informatics
# Hub and resources and services from the National Computational 
# Infrastructure (NCI), which is supported by the Australian Government
# with access facilitated by the University of Sydney.
# 
#########################################################

#PBS -P <project>
#PBS -N bsv-R1-S10-S
#PBS -l walltime=01:30:00
#PBS -l ncpus=532
#PBS -l mem=4845GB
#PBS -W umask=022
#PBS -q normalbw
#PBS -l wd
#PBS -o ./Logs/bsv-R1-S10.o
#PBS -e ./Logs/bsv-R1-S10.e
#PBS -l storage=<lstorage>

module load openmpi/4.0.2
module load nci-parallel/1.0.0


set -e

round=<round>

SCRIPT=./bsv-R1-S10_bqsr_merge_SAMbamba.sh
INPUTS=./Inputs/bqsr_merge.inputs  

NCPUS=14 # NCPUS per task. <=~30X: 14 for normalbw, 24 for normal. Double for 60X. Change CPN= depending on use of normmal or broadwell!

mkdir -p ./Error_capture/BQSR_merge_sambamba_round${round} ./BQSR_bams_sambamba ./BQSR_bams_sambamba/Round${round}

#########################################################
# Do not edit below this line (unless running on a node that 
# does not have 48 CPU, in which case edit the value of 'CPN'
#########################################################

CPN=28 #CPUs per node 
M=$(( CPN / NCPUS )) #tasks per node

sed "s|^|${SCRIPT} |" ${INPUTS} > ${PBS_JOBFS}/input-file

mpirun --np $((M * PBS_NCPUS / 48)) \
        --map-by node:PE=${NCPUS} \
        nci-parallel \
        --verbose \
        --input-file ${PBS_JOBFS}/input-file
